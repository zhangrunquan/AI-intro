{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为了实验的方便,尝试各种方法的代码并未全部保留下来,较好的结果也没有记录在这个文件,本文件没有有价值的信息,仅是优化过程的一小部分失败尝试,拿来作为工作量的参考."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 784) \n",
      "y_train shape: (50000, 10)\n",
      "X_test shape: (10000, 784)\n",
      "y_test shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.models import Model,Sequential\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras import regularizers\n",
    "from keras.initializers import RandomNormal\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "def load_data():\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "    x_train = (x_train.astype(np.float32) - 127.5)/127.5\n",
    "    \n",
    "    # convert shape of x_train from (60000, 28, 28) to (60000, 784) \n",
    "    # 784 columns per row\n",
    "    x_train = x_train.reshape(-1, 784)\n",
    "    x_train=x_train[:50000]\n",
    "    y_train=y_train[:50000]\n",
    "    x_test=x_test.reshape(-1,784)\n",
    "    y_test=to_categorical(y_test)\n",
    "    y_train=to_categorical(y_train)\n",
    "    return (x_train, y_train, x_test, y_test)\n",
    "\n",
    "(X_train, y_train,X_test, y_test)=load_data()\n",
    "\n",
    "print('X_train shape: {0} '.format(X_train.shape))\n",
    "print('y_train shape: {0}'.format(y_train.shape))\n",
    "print('X_test shape: {0}'.format(X_test.shape))\n",
    "print('y_test shape: {0}'.format(y_test.shape))\n",
    "\n",
    "def plot_acc_loss(history):\n",
    "    plt.plot(history.history['acc'],color='blue',label='train_accracy')\n",
    "    plt.plot(history.history['val_acc'],color='red',label='test_accracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.figure()\n",
    "    plt.plot(history.history['loss'],color='blue',label='train_loss')\n",
    "    plt.plot(history.history['val_loss'],color='red',label='test_loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.mnist_loader\n",
    "from imp import reload\n",
    "reload(src.mnist_loader)\n",
    "training_data,_,_=src.mnist_loader.load_data_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000, 784)\n",
      "(250000, 10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x_train_ex,y_train_ex=zip(*training_data)\n",
    "x_train_ex=np.asarray(x_train_ex).reshape(250000,784)\n",
    "y_train_ex=np.asarray(y_train_ex).reshape(250000,-1)\n",
    "print(x_train_ex.shape)\n",
    "print(y_train_ex.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Optimizer\n",
    "import six\n",
    "import copy\n",
    "from six.moves import zip\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.utils.generic_utils import serialize_keras_object\n",
    "from keras.utils.generic_utils import deserialize_keras_object\n",
    "from keras.legacy import interfaces\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "class mySGD(Optimizer):\n",
    "    \"\"\"Stochastic gradient descent optimizer.\n",
    "    Includes support for momentum,\n",
    "    learning rate decay, and Nesterov momentum.\n",
    "    # Arguments\n",
    "        lr: float >= 0. Learning rate.\n",
    "        momentum: float >= 0. Parameter that accelerates SGD\n",
    "            in the relevant direction and dampens oscillations.\n",
    "        decay: float >= 0. Learning rate decay over each update.\n",
    "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, lr=0.01, momentum=0., decay=0.,lmbda=0,\n",
    "                 nesterov=False, **kwargs):\n",
    "        super(mySGD, self).__init__(**kwargs)\n",
    "        with K.name_scope(self.__class__.__name__):\n",
    "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
    "            self.lr = K.variable(lr, name='lr')\n",
    "            self.momentum = K.variable(momentum, name='momentum')\n",
    "            self.decay = K.variable(decay, name='decay')\n",
    "#             self.lmbda=K.variable(lmbda,name='lmbda')\n",
    "        self.initial_decay = decay\n",
    "        self.nesterov = nesterov\n",
    "        self.lmbda=lmbda\n",
    "\n",
    "    @interfaces.legacy_get_updates_support\n",
    "    def get_updates(self, loss, params):\n",
    "        grads = self.get_gradients(loss, params)\n",
    "        self.updates = [K.update_add(self.iterations, 1)]\n",
    "\n",
    "        lr = self.lr\n",
    "        if self.initial_decay > 0:\n",
    "            lr = lr * (1. / (1. + self.decay * K.cast(self.iterations,\n",
    "                                                      K.dtype(self.decay))))\n",
    "#         print(grads)\n",
    "        # momentum\n",
    "        shapes = [K.int_shape(p) for p in params]\n",
    "        moments = [K.zeros(shape) for shape in shapes]\n",
    "        self.weights = [self.iterations] + moments\n",
    "        for p, g, m in zip(params, grads, moments):\n",
    "#             print(params[0].shape)\n",
    "#             print(params[0].read_value())\n",
    "#             with sess.as_default():\n",
    "#                 print(params[0].eval())\n",
    "            \n",
    "#             print(tf.norm(params[0],ord='euclidean'))\n",
    "#             v = self.momentum * m - lr * g  # velocity\n",
    "#             v = self.momentum * m - tf.norm(p,ord=1)*lr /tf.norm(g,ord=1)* g  # velocity\n",
    "            v = self.momentum * m - lr /tf.norm(g,ord=1)* g  # velocity\n",
    "            self.updates.append(K.update(m, v))\n",
    "            \n",
    "            if self.nesterov:\n",
    "                new_p = p + self.momentum * v - lr * g\n",
    "            else:\n",
    "                new_p = p*(1-lmbda) + v\n",
    "#                 new_p = p/tf.norm(p,ord=1) + v\n",
    "            # Apply constraints.\n",
    "            if getattr(p, 'constraint', None) is not None:\n",
    "                new_p = p.constraint(new_p)\n",
    "\n",
    "            self.updates.append(K.update(p, new_p))\n",
    "        return self.updates\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'lr': float(K.get_value(self.lr)),\n",
    "                  'momentum': float(K.get_value(self.momentum)),\n",
    "                  'decay': float(K.get_value(self.decay)),\n",
    "                  'nesterov': self.nesterov}\n",
    "        base_config = super(SGD, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_22 (Dense)             (None, 2000)              1570000   \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 1500)              3001500   \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1000)              1501000   \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 6,578,010\n",
      "Trainable params: 6,578,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "drop_rate=0.6\n",
    "num_train=len(x_train_ex)\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Dense(units=2000,input_shape=(784,),activation='sigmoid'))\n",
    "# model.add(Dense(units=392,input_shape=(784,),activation='sigmoid',kernel_regularizer=regularizers.l2(lmbda)))\n",
    "# model.add(Dropout(rate=drop_rate))\n",
    "l=[1500,1000,500]\n",
    "# l=[191,95,45,30]\n",
    "for i in l:\n",
    "    model.add(Dense(units=i,activation='sigmoid'))\n",
    "#     model.add(Dense(units=i,activation='sigmoid',kernel_initializer=RandomNormal(1,num_train**(0.5))))\n",
    "#     model.add(Dropout(rate=drop_rate))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "learning_rate=0.005\n",
    "\n",
    "lmbda=1/num_train\n",
    "lmbda=0\n",
    "model.compile(loss='categorical_crossentropy',optimizer=mySGD(lr=learning_rate,lmbda=lmbda),metrics=['acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1\n",
    "lmbda=8/num_train\n",
    "lmbda=8/num_train\n",
    "lmbda=0\n",
    "model.compile(loss='categorical_crossentropy',optimizer=mySGD(lr=learning_rate,lmbda=lmbda),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.001\n",
    "model.compile(loss='categorical_crossentropy',optimizer=Adam(),metrics=['acc'])\n",
    "# model.compile(loss='categorical_crossentropy',optimizer=SGD(lr=0.001),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size=128\n",
    "# epochs=50\n",
    "# history=model.fit(X_train,y_train,\n",
    "#           batch_size=batch_size,\n",
    "#          epochs=epochs,\n",
    "#          validation_data=[X_test,y_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 250000 samples, validate on 10000 samples\n",
      "Epoch 1/15\n",
      "250000/250000 [==============================] - 5s 20us/step - loss: 0.3758 - acc: 0.8839 - val_loss: 0.4937 - val_acc: 0.8848 loss: 0.3763  - ETA: 0s - loss: 0.3769 - acc:\n",
      "Epoch 2/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3734 - acc: 0.8847 - val_loss: 0.4955 - val_acc: 0.8837\n",
      "Epoch 3/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3710 - acc: 0.8854 - val_loss: 0.4979 - val_acc: 0.8837\n",
      "Epoch 4/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3686 - acc: 0.8861 - val_loss: 0.5002 - val_acc: 0.8833\n",
      "Epoch 5/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3662 - acc: 0.8868 - val_loss: 0.5019 - val_acc: 0.8823\n",
      "Epoch 6/15\n",
      "250000/250000 [==============================] - 5s 20us/step - loss: 0.3638 - acc: 0.8877 - val_loss: 0.5024 - val_acc: 0.8824\n",
      "Epoch 7/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3614 - acc: 0.8883 - val_loss: 0.4968 - val_acc: 0.8836\n",
      "Epoch 8/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3591 - acc: 0.8890 - val_loss: 0.4969 - val_acc: 0.8839\n",
      "Epoch 9/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3567 - acc: 0.8896 - val_loss: 0.5011 - val_acc: 0.8827\n",
      "Epoch 10/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3544 - acc: 0.8905 - val_loss: 0.5077 - val_acc: 0.8816\n",
      "Epoch 11/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3520 - acc: 0.8912 - val_loss: 0.5005 - val_acc: 0.8843\n",
      "Epoch 12/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3496 - acc: 0.8920 - val_loss: 0.5200 - val_acc: 0.8755\n",
      "Epoch 13/15\n",
      "250000/250000 [==============================] - 5s 20us/step - loss: 0.3474 - acc: 0.8927 - val_loss: 0.5018 - val_acc: 0.8841\n",
      "Epoch 14/15\n",
      "250000/250000 [==============================] - 5s 19us/step - loss: 0.3451 - acc: 0.8936 - val_loss: 0.5031 - val_acc: 0.8842\n",
      "Epoch 15/15\n",
      "250000/250000 [==============================] - 5s 20us/step - loss: 0.3428 - acc: 0.8944 - val_loss: 0.5043 - val_acc: 0.8840\n"
     ]
    }
   ],
   "source": [
    "batch_size=512\n",
    "epochs=15\n",
    "history=model.fit(x_train_ex,y_train_ex,\n",
    "          batch_size=batch_size,\n",
    "         epochs=epochs,\n",
    "         validation_data=[X_test,y_test]\n",
    "                 ,shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 尝试更强的数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(data, targets, batch_size):\n",
    "    batches = len(data)//batch_size\n",
    "    while(True):\n",
    "        for i in range(batches):\n",
    "            X = data[i*batch_size : (i+1)*batch_size]\n",
    "            Y = targets[i*batch_size : (i+1)*batch_size]\n",
    "            yield (X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_164 (Dense)            (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 186)               73098     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 93)                17391     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 47)                4418      \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 25)                1200      \n",
      "_________________________________________________________________\n",
      "dense_170 (Dense)            (None, 10)                260       \n",
      "=================================================================\n",
      "Total params: 1,019,527\n",
      "Trainable params: 1,019,527\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "lmbda=0.00003\n",
    "# model.add(Dense(units=2500,input_shape=(784,),activation='sigmoid'))\n",
    "# model.add(Dense(units=784,input_shape=(784,),activation='sigmoid'))\n",
    "model.add(Dense(units=784,input_shape=(784,),activation='sigmoid',kernel_regularizer=regularizers.l2(lmbda)))\n",
    "# model.add(Dropout(rate=0.2))\n",
    "# l=[2000,1500,1000,500]\n",
    "# l=[1500,1000,500]\n",
    "l=[392,186,93,47,25]\n",
    "for i in l:\n",
    "#     model.add(Dense(units=i,activation='sigmoid'))\n",
    "    model.add(Dense(units=i,activation='sigmoid',kernel_regularizer=regularizers.l2(lmbda)))\n",
    "#     model.add(Dropout(rate=0.2))\n",
    "model.add(Dense(units=10,activation='softmax'))\n",
    "model.summary()\n",
    "\n",
    "learning_rate=0.0005\n",
    "model.compile(loss='categorical_crossentropy',optimizer=mySGD(lr=learning_rate),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1, 28, 28)\n",
      "(10000, 784)\n",
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "data_gen=ImageDataGenerator(data_format='channels_first',\n",
    "#                            zca_whitening=True,\n",
    "#                            rotation_range=7.5,\n",
    "#                            width_shift_range=.05,\n",
    "#                            height_shift_range=.05,\n",
    "                           )\n",
    "# data_gen.fit(x_train)\n",
    "X_train=X_train.reshape(50000,1,28,28)\n",
    "X_test=X_test.reshape(-1,784)\n",
    "y_train=y_train.reshape(-1,10)\n",
    "y_test=y_test.reshape(-1,10)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "data_gen.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dg_wrapper(data_gen,X_train,y_train,batch_size):\n",
    "    while(True):\n",
    "        dg=data_gen.flow(X_train,y_train,batch_size=batch_size)\n",
    "        for i in range(len(X_train)// batch_size):\n",
    "            d=next(dg)\n",
    "            x,y=d[0],d[1]\n",
    "            x=x.reshape(batch_size,784)\n",
    "            y=y.reshape(batch_size,-1)\n",
    "            yield (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.0003\n",
    "model.compile(loss='categorical_crossentropy',optimizer=mySGD(lr=learning_rate),metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1915 - acc: 0.6072 - val_loss: 1.2996 - val_acc: 0.5357\n",
      "Epoch 2/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1538 - acc: 0.6210 - val_loss: 1.2836 - val_acc: 0.5517\n",
      "Epoch 3/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1308 - acc: 0.6282 - val_loss: 1.2538 - val_acc: 0.5662\n",
      "Epoch 4/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1148 - acc: 0.6335 - val_loss: 1.2848 - val_acc: 0.5588\n",
      "Epoch 5/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1042 - acc: 0.6349 - val_loss: 1.2928 - val_acc: 0.5604\n",
      "Epoch 6/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.0971 - acc: 0.6370 - val_loss: 1.3324 - val_acc: 0.5639\n",
      "Epoch 7/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.0944 - acc: 0.6384 - val_loss: 1.3618 - val_acc: 0.5639\n",
      "Epoch 8/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.0947 - acc: 0.6389 - val_loss: 1.4166 - val_acc: 0.5541\n",
      "Epoch 9/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.0961 - acc: 0.6374 - val_loss: 1.4648 - val_acc: 0.5502\n",
      "Epoch 10/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1000 - acc: 0.6344 - val_loss: 1.5017 - val_acc: 0.5517\n",
      "Epoch 11/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1037 - acc: 0.6340 - val_loss: 1.5421 - val_acc: 0.5427\n",
      "Epoch 12/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1077 - acc: 0.6316 - val_loss: 1.5681 - val_acc: 0.5427\n",
      "Epoch 13/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1129 - acc: 0.6299 - val_loss: 1.5907 - val_acc: 0.5461\n",
      "Epoch 14/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1179 - acc: 0.6280 - val_loss: 1.6373 - val_acc: 0.5444\n",
      "Epoch 15/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1190 - acc: 0.6277 - val_loss: 1.6751 - val_acc: 0.5435\n",
      "Epoch 16/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1230 - acc: 0.6263 - val_loss: 1.6975 - val_acc: 0.5481\n",
      "Epoch 17/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1271 - acc: 0.6244 - val_loss: 1.7292 - val_acc: 0.5427\n",
      "Epoch 18/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1318 - acc: 0.6241 - val_loss: 1.7507 - val_acc: 0.5397\n",
      "Epoch 19/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1345 - acc: 0.6217 - val_loss: 1.7684 - val_acc: 0.5387\n",
      "Epoch 20/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1354 - acc: 0.6212 - val_loss: 1.7627 - val_acc: 0.5420\n",
      "Epoch 21/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1374 - acc: 0.6196 - val_loss: 1.8066 - val_acc: 0.5389\n",
      "Epoch 22/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1403 - acc: 0.6198 - val_loss: 1.7897 - val_acc: 0.5422\n",
      "Epoch 23/50\n",
      "5000/5000 [==============================] - 20s 4ms/step - loss: 1.1407 - acc: 0.6184 - val_loss: 1.7998 - val_acc: 0.5393\n",
      "Epoch 24/50\n",
      "5000/5000 [==============================] - 21s 4ms/step - loss: 1.1420 - acc: 0.6150 - val_loss: 1.8073 - val_acc: 0.5394\n",
      "Epoch 25/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1423 - acc: 0.6165 - val_loss: 1.8041 - val_acc: 0.5407\n",
      "Epoch 26/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1430 - acc: 0.6153 - val_loss: 1.8176 - val_acc: 0.5368\n",
      "Epoch 27/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1452 - acc: 0.6142 - val_loss: 1.8098 - val_acc: 0.5375\n",
      "Epoch 28/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1438 - acc: 0.6154 - val_loss: 1.8073 - val_acc: 0.5387\n",
      "Epoch 29/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1440 - acc: 0.6153 - val_loss: 1.8226 - val_acc: 0.5393\n",
      "Epoch 30/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1461 - acc: 0.6156 - val_loss: 1.8198 - val_acc: 0.5387\n",
      "Epoch 31/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1446 - acc: 0.6159 - val_loss: 1.8286 - val_acc: 0.5384\n",
      "Epoch 32/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1465 - acc: 0.6141 - val_loss: 1.8304 - val_acc: 0.5396\n",
      "Epoch 33/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1464 - acc: 0.6127 - val_loss: 1.8370 - val_acc: 0.5344\n",
      "Epoch 34/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1458 - acc: 0.6125 - val_loss: 1.8004 - val_acc: 0.5404\n",
      "Epoch 35/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1453 - acc: 0.6134 - val_loss: 1.8114 - val_acc: 0.5421\n",
      "Epoch 36/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1457 - acc: 0.6123 - val_loss: 1.8138 - val_acc: 0.5381\n",
      "Epoch 37/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1453 - acc: 0.6138 - val_loss: 1.8430 - val_acc: 0.5338\n",
      "Epoch 38/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1451 - acc: 0.6128 - val_loss: 1.8061 - val_acc: 0.5403\n",
      "Epoch 39/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1439 - acc: 0.6145 - val_loss: 1.8048 - val_acc: 0.5411\n",
      "Epoch 40/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1441 - acc: 0.6138 - val_loss: 1.8014 - val_acc: 0.5424\n",
      "Epoch 41/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1468 - acc: 0.6154 - val_loss: 1.8242 - val_acc: 0.5395\n",
      "Epoch 42/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1474 - acc: 0.6130 - val_loss: 1.7959 - val_acc: 0.5387\n",
      "Epoch 43/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1485 - acc: 0.6133 - val_loss: 1.8069 - val_acc: 0.5443\n",
      "Epoch 44/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1459 - acc: 0.6121 - val_loss: 1.8067 - val_acc: 0.5384\n",
      "Epoch 45/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1463 - acc: 0.6149 - val_loss: 1.8058 - val_acc: 0.5409\n",
      "Epoch 46/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1465 - acc: 0.6151 - val_loss: 1.8282 - val_acc: 0.5364\n",
      "Epoch 47/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1478 - acc: 0.6129 - val_loss: 1.7974 - val_acc: 0.5391\n",
      "Epoch 48/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1492 - acc: 0.6122 - val_loss: 1.8154 - val_acc: 0.5351\n",
      "Epoch 49/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1486 - acc: 0.6140 - val_loss: 1.8067 - val_acc: 0.5403\n",
      "Epoch 50/50\n",
      "5000/5000 [==============================] - 19s 4ms/step - loss: 1.1509 - acc: 0.6124 - val_loss: 1.8343 - val_acc: 0.5361\n"
     ]
    }
   ],
   "source": [
    "batch_size=10\n",
    "epochs=50\n",
    "# steps_per_epoch=3\n",
    "# data_gen.flow(X_train,y_train,batch_size=batch_size)\n",
    "history=model.fit_generator(dg_wrapper(data_gen,X_train,y_train,batch_size),\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=(len(X_train)// batch_size),\n",
    "        validation_data=data_generator(X_test,y_test,batch_size),\n",
    "        validation_steps=len(X_test)//batch_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_acc_loss(history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
